Storm:风暴
--------------
	1.流计算,源源不断。
		mapreduce:batch
		topology
		Spout

	2.
	3.
	4.

stream:data stream.
-------------------
	
storm介绍
--------------
	分布式、实时大数据处理系统。是流数据计算框架。高速攫取数据。
	stateless是无状态的，通过zk管理分布式环境和集群的状态。
	可以执行各种数据的实时并行计算。

	hadoop实时计算欠缺，storm没有持久化处理。


storm vs hadoop

	Storm					Hadoop
	----------------------------------------
	实时计算				批处理

	无状态的				有状态的

	基于zk的主从模式		master:appmaster + yarnchild
	流处理每秒处理数万消息	hadoop mr框架计算海量数据花费数分钟/

	topology运行直到user或	mr按序执行，最终会执行结束。
	程序故障。

	分布式+容错				分布式+容错

	nimub或supervisor宕		如果mr停止，所有data就丢失了。
	机后，重启后从stop的
	地方继续，没有影响的。


storm优势
--------------
	2.开源、友好、健壮，适用于大小公司。
	3.容错、灵活、可靠，支持跨语言。
	4.支持实时流计算。
	5.快，强大的数据处理能力。
	6.低延迟。
	7.操作智能化
	8.确保数据在集群故障或数据丢失时，至少处理一次。

组件
---------------	
	1.Tuple
		storm中主要数据结构，有序元素的列表。默认，tuple支持所有数据类型。
		通常以“，”分割进行建模兵传递给storm集群。
	2.Stream
		无需的Tuple序列。
	3.Spout
		Stream的源头，从原生数据源接收数据，通常是tweet api或者是kafka queue.
		ISpout是核心接口。
	4.Bolt
		逻辑处理单元。Spout的输出进入bolt。Bolt处理并产生新的tuple。bolt可以执行
		聚合、连接、过滤以及和数据源（数据库）交互。
		IBolt是Storm核心接口。

Topology
--------------
	Spout和Bolt连接在一起形成topology.可以理解成有向图，
	顶点用来计算，边是数据流动。

	起始于spout，输出到一个或多个bolt，bolt是最小的数据处理逻辑，
	bolt的输出也可以是其他bolt的输入。

	topolgy保持始终运行的状态。storm在给定的时间可以运行任意数量的
	top.






Nimbus
---------------
	master，负责top运行，分析top，并收集task运行情况。分发task给可用
	的supervisor。分发数据给work节点。指派任务给工作节点，监听失败。

supervisor
----------------
	有着一个或多个工作进程，代理工作进程的task。
	工作进程会产生多个执行线程来运行task。使用的是内部消息分发系统进行nimbus和
	supervisor之间通信。

	接收nimbus指令，可以多个work process，管理工作进程来完成指派的task。

Worker process
-------------
	工作进程，storm在所有worker node(工作进程)上尽可能平均传播task.
	worker的角色在新job到达时，进行监听、启动、停止。

	执行特定的top相关的task，本省不执行。需要创建executor线程来运行task。
	一个work process可以有多个executor线程。

Exccutor
-------------
	执行线程,仅仅是worker process创建的一个线程。
	每个执行线程执行一个或多个task，这些task是特定的spout的或者是bolt的。

Task
-------------
	执行实际上的数据处理工作。或者spout，或者是bolt.


zk
-------------
	维护nimbus和supervisor的状态。


安装storm
-------------------
	1.准备
		jdk + zookeeper
	2.storm安装
		下载apache-storm-1.0.1.tar.gz + apache-storm-1.0.1.-src-tar.gz
	3.tar
	4.移动文件
		$>mv /soft/..
	5.配置环境变量
		[/etc/environment]
		path
		STORM_HOME=
	6.配置storm
		[conf/yaml]
		storm.zookeeper.servers:
			 - "s200"
			 - "s300"
			 - "s400"
		storm.local.dir: "/home/ubuntu/storm"
		nimbus.host: "s100"
		supervisor.slots.ports:
			- 6700
			- 6701
			- 6703
		# 
		# nimbus.seeds: ["host1", "host2", "host3"]
		# 
		# 
		# ##### These may optionally be filled in:
		#    
		## List of custom serializations
		# topology.kryo.register:
		#     - org.mycompany.MyType
		#     - org.mycompany.MyType2: org.mycompany.MyType2Serializer
		#
		## List of custom kryo decorators
		# topology.kryo.decorators:
		#     - org.mycompany.MyDecorator
		#
		## Locations of the drpc servers
		# drpc.servers:
		#     - "server1"
		#     - "server2"

		## Metrics Consumers
		# topology.metrics.consumer.register:
		#   - class: "org.apache.storm.metric.LoggingMetricsConsumer"
		#     parallelism.hint: 1
		#   - class: "org.mycompany.MyMetricsConsumer"
		#     parallelism.hint: 1
		#     argument:
		#       - endpoint: "metrics-collector.mycompany.org"
		
	7.启动zk集群
		$>zkServer.sh start
		$>zkServer.sh status

	8.启动storm集成
		$>storm nimbus			//master
		$>storm supervisor		//slave
		$>storm ui				//ui


storm完全分布式配置
----------------
	1.storm.yaml
		...
		nimbus.host="s100"
		...
	2.分发软件包和配置
		...
	3.单独登录到每个主机，执行需要的命令，启动相关进程·
		$>storm nimbus				//s100
		$>storm ui					//s100

		$>ssh s200 storm supervisor	//s100
			...
	4.

storm应用
-----------------
	1.创建java项目
	2.引入类库
		D:\downloads\bigdata\apache-storm-1.0.1\lib\asm-5.0.3.jar
		D:\downloads\bigdata\apache-storm-1.0.1\lib\clojure-1.7.0.jar
		D:\downloads\bigdata\apache-storm-1.0.1\lib\disruptor-3.3.2.jar
		D:\downloads\bigdata\apache-storm-1.0.1\lib\kryo-3.0.3.jar
		D:\downloads\bigdata\apache-storm-1.0.1\lib\log4j-api-2.1.jar
		D:\downloads\bigdata\apache-storm-1.0.1\lib\log4j-core-2.1.jar
		D:\downloads\bigdata\apache-storm-1.0.1\lib\log4j-over-slf4j-1.6.6.jar
		D:\downloads\bigdata\apache-storm-1.0.1\lib\log4j-slf4j-impl-2.1.jar
		D:\downloads\bigdata\apache-storm-1.0.1\lib\minlog-1.3.0.jar
		D:\downloads\bigdata\apache-storm-1.0.1\lib\objenesis-2.1.jar
		D:\downloads\bigdata\apache-storm-1.0.1\lib\reflectasm-1.10.1.jar
		D:\downloads\bigdata\apache-storm-1.0.1\lib\servlet-api-2.5.jar
		D:\downloads\bigdata\apache-storm-1.0.1\lib\slf4j-api-1.7.7.jar
		D:\downloads\bigdata\apache-storm-1.0.1\lib\storm-core-1.0.1.jar
		D:\downloads\bigdata\apache-storm-1.0.1\lib\storm-rename-hack-1.0.1.jar
	3.创建CallSpout类
		[CallSpout.java]
		package com.it18zhang.storm;

		import java.util.ArrayList;
		import java.util.List;
		import java.util.Map;
		import java.util.Random;

		import org.apache.storm.spout.SpoutOutputCollector;
		import org.apache.storm.task.TopologyContext;
		import org.apache.storm.topology.IRichSpout;
		import org.apache.storm.topology.OutputFieldsDeclarer;
		import org.apache.storm.tuple.Fields;
		import org.apache.storm.tuple.Values;

		/**
		 * CallSpout
		 */
		public class CallSpout implements IRichSpout {
			//创建tuple给bolt
			private SpoutOutputCollector collector;
			
			private boolean completed = false;
			
			//创建top上下文对象，含有top的数据
			private TopologyContext context;
			
			// Create instance for Random class.
			private Random rand = new Random();
			
			private Integer idx = 0;

			/**
			 * 
			 */
			public void open(Map conf, TopologyContext context, SpoutOutputCollector collector) {
				this.context = context;
				this.collector = collector;
			}

			public void nextTuple() {
				if (this.idx <= 1000) {
					List<String> mobileNumbers = new ArrayList<String>();
					mobileNumbers.add("1234123401");
					mobileNumbers.add("1234123402");
					mobileNumbers.add("1234123403");
					mobileNumbers.add("1234123404");
					Integer localIdx = 0;
					while (localIdx++ < 100 && this.idx++ < 1000) {
						//随机提取caller
						String fromMobileNumber = mobileNumbers.get(rand.nextInt(4));
						//随机提取receiver
						String toMobileNumber = mobileNumbers.get(rand.nextInt(4));
						//
						while (fromMobileNumber == toMobileNumber) {
							toMobileNumber = mobileNumbers.get(rand.nextInt(4));
						}
						//
						Integer duration = rand.nextInt(60);
						
						//输出tuple
						this.collector.emit(new Values(fromMobileNumber, toMobileNumber, duration));
					}
				}
			}

			/**
			 * 
			 */
			public void declareOutputFields(OutputFieldsDeclarer declarer) {
				declarer.declare(new Fields("from", "to", "duration"));
			}

			// Override all the interface methods
			@Override
			public void close() {
			}

			public boolean isDistributed() {
				return false;
			}

			@Override
			public void activate() {
			}

			@Override
			public void deactivate() {
			}

			@Override
			public void ack(Object msgId) {
			}

			@Override
			public void fail(Object msgId) {
			}

			@Override
			public Map<String, Object> getComponentConfiguration() {
				return null;
			}
		}

	4.CallLogCreatorBolt.java
		package com.it18zhang.storm;

		import java.util.Map;

		import org.apache.storm.task.OutputCollector;
		import org.apache.storm.task.TopologyContext;
		import org.apache.storm.topology.IRichBolt;
		import org.apache.storm.topology.OutputFieldsDeclarer;
		import org.apache.storm.tuple.Fields;
		import org.apache.storm.tuple.Tuple;
		import org.apache.storm.tuple.Values;

		/**
		 * CallLogCreatorBolt 
		 */
		public class CallLogCreatorBolt implements IRichBolt {
			
			private static final long serialVersionUID = -6584178420615831075L;
			
			//收集数据，发送tuple
			private OutputCollector collector;

			public void prepare(Map conf, TopologyContext context, OutputCollector collector) {
				this.collector = collector;
			}

			/**
			 * 计算
			 */
			public void execute(Tuple tuple) {
				//from
				String from = tuple.getString(0);
				//to
				String to = tuple.getString(1);
				//dur
				Integer duration = tuple.getInteger(2);
				//数据处理
				collector.emit(new Values(from + " - " + to, duration));
			}

			public void cleanup() {
			}

			/**
			 * 定义 field
			 */
			public void declareOutputFields(OutputFieldsDeclarer declarer) {
				declarer.declare(new Fields("call", "duration"));
			}

			public Map<String, Object> getComponentConfiguration() {
				return null;
			}
		}

	5.CallLogCounterBolt.java
		package com.it18zhang.storm;

		import java.util.HashMap;
		import java.util.Map;

		import org.apache.storm.task.OutputCollector;
		import org.apache.storm.task.TopologyContext;
		import org.apache.storm.topology.IRichBolt;
		import org.apache.storm.topology.OutputFieldsDeclarer;
		import org.apache.storm.tuple.Fields;
		import org.apache.storm.tuple.Tuple;

		/**
		 * Counter
		 */
		public class CallLogCounterBolt implements IRichBolt {
			
			private static final long serialVersionUID = -4598302147870421925L;
			
			Map<String, Integer> counterMap;
			
			private OutputCollector collector;

			public void prepare(Map conf, TopologyContext context, OutputCollector collector) {
				this.counterMap = new HashMap<String, Integer>();
				this.collector = collector;
			}

			public void execute(Tuple tuple) {
				//call
				String call = tuple.getString(0);
				//dur
				Integer duration = tuple.getInteger(1);
				
				if (!counterMap.containsKey(call)) {
					counterMap.put(call, 1);
				} else {
					Integer c = counterMap.get(call) + 1;
					counterMap.put(call, c);
				}
				//确认
				collector.ack(tuple);
			}

			public void cleanup() {
				for (Map.Entry<String, Integer> entry : counterMap.entrySet()) {
					System.out.println(entry.getKey() + " : " + entry.getValue());
				}
			}

			@Override
			public void declareOutputFields(OutputFieldsDeclarer declarer) {
				declarer.declare(new Fields("call"));
			}

			@Override
			public Map<String, Object> getComponentConfiguration() {
				return null;
			}
		}
	6.StormApp.java	//在本地集群模式运行
		package com.it18zhang.storm;

		import org.apache.storm.Config;
		import org.apache.storm.LocalCluster;
		import org.apache.storm.topology.TopologyBuilder;
		import org.apache.storm.tuple.Fields;

		public class StormApp {

			public static void main(String[] args) throws Exception {
				//
				Config config = new Config();
				//
				config.setDebug(true);
				//
				TopologyBuilder builder = new TopologyBuilder();
				
				//设置spout
				builder.setSpout("call-spout", new CallSpout());
				
				//setBolt
				builder.setBolt("call-log-creator-bolt", new CallLogCreatorBolt()).shuffleGrouping("call-spout");
				
				//setBolt
				builder.setBolt("call-log-counter-bolt", new CallLogCounterBolt()).fieldsGrouping("call-log-creator-bolt",new Fields("call"));
				
				//本地集群
				LocalCluster cluster = new LocalCluster();
				
				//提交topology
				cluster.submitTopology("StormApp", config, builder.createTopology());
				//
				Thread.sleep(10000);
				
				//停止集群
				cluster.shutdown();
			}
		}


storm spout
-----------------
	跟踪消息，前提是有msgid,类型不限，bolt中调用cellector的ack(msgid)或者fail(msgid)方法，
	方法最终会回传给spout,识别消息是否处理成功。



在单节点集群上部署topology.
---------------------------
	1.Spout + bolt不变
	2.修改App
		[StormAppInCluster.java]
		package com.it18zhang.storm;

		import org.apache.storm.Config;
		import org.apache.storm.StormSubmitter;
		import org.apache.storm.topology.TopologyBuilder;
		import org.apache.storm.tuple.Fields;

		public class StormAppInCluster {

			public static void main(String[] args) throws Exception {
				//
				Config config = new Config();
				//
				config.setDebug(true);
				//
				TopologyBuilder builder = new TopologyBuilder();
				
				//设置spout
				builder.setSpout("spout", new CallSpout());
				
				//setBolt
				builder.setBolt("bolt-1", new CallLogCreatorBolt()).shuffleGrouping("spout");
				
				//setBolt
				builder.setBolt("bolt-2", new CallLogCounterBolt()).fieldsGrouping("bolt-1",new Fields("call"));
				
				//
				StormSubmitter.submitTopology("StormApp", config, builder.createTopology());
			}
		}

	3.导出jar
		略
	4.提交给storm集群
		1)单节点的storm集群
			$>storm nimbus &
			$>storm supervisor &
			$>storm ui &
	5.提交top
		$>storm jar xxx.jar xxx.x.x


storm操作模式
-------------------
	1.local mode
		top运行在本地的jvm中。使用单个jvm模拟集群。
		LocalCluster local = ...
		local.submitTopology("LearningStormToplogy", conf, builder.createTopology());		//本地模式
	2.remote mode
		使用storm client提交top到master，nimbus分发代码。
		
		//在远程storm cluster上提交top
		StormSubmitter.submitTopology(args[0], conf, builder.createTopology());
		


编写top，不是到storm完全分布式集群上
-------------------------------------	
	1.new project
	2.add lib
	3.创建Spout
		package com.it18zhang.storm2;

		import java.util.HashMap;
		import java.util.Map;
		import java.util.Random;

		import org.apache.storm.spout.SpoutOutputCollector;
		import org.apache.storm.task.TopologyContext;
		import org.apache.storm.topology.OutputFieldsDeclarer;
		import org.apache.storm.topology.base.BaseRichSpout;
		import org.apache.storm.tuple.Fields;
		import org.apache.storm.tuple.Values;

		/**
		 * MySpout
		 */
		public class MySpout extends BaseRichSpout {

			private static final long serialVersionUID = 1L;
			private SpoutOutputCollector spoutOutputCollector;
			private static final Map<Integer, String> map = new HashMap<Integer, String>();

			static {
				map.put(0, "google");
				map.put(1, "facebook");
				map.put(2, "twitter");
				map.put(3, "youtube");
				map.put(4, "linkedin");
			}

			public void open(Map conf, TopologyContext context, SpoutOutputCollector spoutOutputCollector) {
				this.spoutOutputCollector = spoutOutputCollector;
			}

			public void nextTuple() {
				final Random rand = new Random();
				int randomNumber = rand.nextInt(5);
				spoutOutputCollector.emit(new Values(map.get(randomNumber)));

			}

			public void declareOutputFields(OutputFieldsDeclarer declarer) {
				declarer.declare(new Fields("site"));
			}
		}

	4.创建Bolt
		package com.it18zhang.storm2;

		import org.apache.storm.topology.BasicOutputCollector;
		import org.apache.storm.topology.OutputFieldsDeclarer;
		import org.apache.storm.topology.base.BaseBasicBolt;
		import org.apache.storm.tuple.Tuple;

		/**
		 * MyBolt
		 */
		public class MyBolt extends BaseBasicBolt {

			private static final long serialVersionUID = -594733280504307288L;

			public void execute(Tuple input, BasicOutputCollector collector) {
				String site = input.getStringByField("site");
				System.out.println("site : " + site);
			}

			public void declareOutputFields(OutputFieldsDeclarer declarer) {
			}
		}
	5.创App
		package com.it18zhang.storm2;

		import org.apache.storm.Config;
		import org.apache.storm.StormSubmitter;
		import org.apache.storm.topology.TopologyBuilder;

		/**
		 * remove mode!
		 */
		public class MyApp {

			public static void main(String[] args) throws Exception {
				TopologyBuilder builder = new TopologyBuilder();
				builder.setSpout("LearningStormSpout", new MySpout(), 4);
				builder.setBolt("LearningStormBolt", new MyBolt(), 2).shuffleGrouping("LearningStormSpout");

				Config conf = new Config();
				conf.setNumWorkers(3);
				try {
					StormSubmitter.submitTopology("MyStormApp", conf, builder.createTopology());
					System.out.println("over!!!");
				} catch (Exception invalidTopologyException) {
					System.out.println(invalidTopologyException);
				}
			}
		}

	6.整理storm集群
		...
	7.导入jar
		...
	8.在client提交top到storm集群.
		$>s100
		$>


